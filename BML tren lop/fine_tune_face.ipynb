{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D,AveragePooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.utils import np_utils\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import applications\n",
    "from keras import initializers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=224\n",
    "num_classes=10\n",
    "\n",
    "INIT_LR = 0.0001\n",
    "BS = 16\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet=applications.mobilenet.MobileNet(input_shape=(img_size,img_size,3), alpha=1.0, depth_multiplier=1, dropout=0.1,\n",
    "                                           include_top=False, weights='imagenet', input_tensor=None)\n",
    "\n",
    "\n",
    "#mobilenet.summary()\n",
    "\n",
    "#freezing all layer\n",
    "#mobilenet.trainable = False\n",
    "\n",
    "#freezing some first layers\n",
    "#mobilenet.get_layer('conv1').trainable = False\n",
    "#mobilenet.get_layer('conv_dw_2').trainable = False\n",
    "\n",
    "\n",
    "#freezing many layers\n",
    "fine_tune_at=100\n",
    "for layer in mobilenet.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=mobilenet.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(512,activation='relu')(x)\n",
    "x=Dense(128,activation='relu')(x) \n",
    "pred=Dense(num_classes, activation='softmax')(x) #final layer with softmax activation\n",
    "model=Model(inputs=mobilenet.input,outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train='data/Face_Train'\n",
    "path_test='data/Face_Test'\n",
    "\n",
    "import os\n",
    "def get_images(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    k=0\n",
    "    for subdir,_, files in os.walk(path):\n",
    "        if subdir==path:\n",
    "            continue\n",
    "        for line in files:\n",
    "            if line.startswith('.'):\n",
    "                continue\n",
    "            fields = subdir.strip().split('/')\n",
    "            file_name=os.path.join(subdir, line)\n",
    "            label=fields[-1]\n",
    "            image = cv2.imread(file_name,1)\n",
    "            image=cv2.resize(image,(img_size,img_size))\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "        k=k+1\n",
    "    return images, labels\n",
    "\n",
    "images_train,label_train=get_images(path_train)\n",
    "images_test,label_test=get_images(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(images_train)\n",
    "y_train=np.array(label_train)\n",
    "\n",
    "x_test=np.array(images_test)\n",
    "y_test=np.array(label_test)\n",
    "\n",
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-c640f748f4f4>:15: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.8227 - accuracy: 0.4110\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.16000, saving model to /Users/uynq/Desktop/AI_Academy/BML_Online/BML15/Codes/saved_models/model-01-0.160.hdf5\n",
      "19/19 [==============================] - 22s 1s/step - loss: 1.8227 - accuracy: 0.4110 - val_loss: 2.4645 - val_accuracy: 0.1600\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.1313 - accuracy: 0.6370\n",
      "Epoch 00002: val_accuracy improved from 0.16000 to 0.25000, saving model to /Users/uynq/Desktop/AI_Academy/BML_Online/BML15/Codes/saved_models/model-02-0.250.hdf5\n",
      "19/19 [==============================] - 22s 1s/step - loss: 1.1313 - accuracy: 0.6370 - val_loss: 2.2498 - val_accuracy: 0.2500\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.7662 - accuracy: 0.7808\n",
      "Epoch 00003: val_accuracy did not improve from 0.25000\n",
      "19/19 [==============================] - 22s 1s/step - loss: 0.7662 - accuracy: 0.7808 - val_loss: 2.2812 - val_accuracy: 0.2200\n",
      "Epoch 4/50\n",
      "10/19 [==============>...............] - ETA: 9s - loss: 0.5099 - accuracy: 0.8784 "
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "path1=os.getcwd()+ '/saved_models/'\n",
    "filepath=path1+\"model-{epoch:02d}-{val_accuracy:.3f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "  \n",
    "H = model.fit_generator(aug.flow(x_train, y_train, batch_size=BS),\n",
    "\tvalidation_data=(x_test, y_test), steps_per_epoch=len(x_train) // BS,\n",
    "\tepochs=EPOCHS,callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
